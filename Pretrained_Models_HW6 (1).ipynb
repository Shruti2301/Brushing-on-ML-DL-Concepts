{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#pip install datasets\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from transformers.keras_callbacks import KerasMetricCallback\n",
        "\n",
        "def batch_predict_sentiment(texts, tokenizer, model, batch_size=10):\n",
        "    total_texts = len(texts)\n",
        "    predicted_sentiments = []\n",
        "\n",
        "    for i in range(0, total_texts, batch_size):\n",
        "        texts_batch = texts[i:i + batch_size]\n",
        "        inputs = tokenizer(texts_batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "        print(f\"Predicting batch {i // batch_size + 1}/{(total_texts + batch_size - 1) // batch_size}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        predicted_classes = torch.argmax(outputs.logits, dim=1).tolist()\n",
        "        predicted_sentiments.extend(predicted_classes)\n",
        "\n",
        "    return predicted_sentiments\n",
        "\n",
        "def calculate_accuracy(predicted_sentiments, actual_labels):\n",
        "    correct_predictions = sum(1 for pred, label in zip(predicted_sentiments, actual_labels) if pred == label)\n",
        "    total_predictions = len(actual_labels)\n",
        "    accuracy = correct_predictions / total_predictions * 100\n",
        "    return accuracy\n",
        "\n",
        "def predict_model(test_data, model_name):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "    batch_predicted_sentiments = batch_predict_sentiment(test_data['text'], tokenizer, model)\n",
        "    actual_labels = test_data['label']\n",
        "\n",
        "    accuracy = calculate_accuracy(batch_predicted_sentiments, actual_labels)\n",
        "    print(f\"The accuracy achieved for predictions using {model_name} is {accuracy:.2f}%\")\n",
        "    return accuracy\n",
        "\n",
        "def main():\n",
        "    imdb = load_dataset(\"imdb\")\n",
        "    small_test_dataset = imdb[\"test\"].shuffle(seed=42).select(range(200))\n",
        "\n",
        "    # Predict using GPT2\n",
        "    gpt2_accuracy = predict_model(small_test_dataset, \"mnoukhov/gpt2-imdb-sentiment-classifier\")\n",
        "\n",
        "    # Predict using RoBERTa\n",
        "    roberta_accuracy = predict_model(small_test_dataset, \"abhishek/autonlp-imdb-roberta-base-3662644\")\n",
        "\n",
        "    # Predict using BERT\n",
        "    bert_accuracy = predict_model(small_test_dataset, \"bert-base-uncased\")\n",
        "\n",
        "    # Comparing accuracies\n",
        "    print(\"\\nComparing accuracies:\")\n",
        "    print(f\"GPT2 Accuracy: {gpt2_accuracy:.2f}%\")\n",
        "    print(f\"RoBERTa Accuracy: {roberta_accuracy:.2f}%\")\n",
        "    print(f\"BERT Accuracy: {bert_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RSRxTsnL8KA",
        "outputId": "7873191c-c400-43b9-c627-f5dc24f4c2dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting batch 1/20\n",
            "Predicting batch 2/20\n",
            "Predicting batch 3/20\n",
            "Predicting batch 4/20\n",
            "Predicting batch 5/20\n",
            "Predicting batch 6/20\n",
            "Predicting batch 7/20\n",
            "Predicting batch 8/20\n",
            "Predicting batch 9/20\n",
            "Predicting batch 10/20\n",
            "Predicting batch 11/20\n",
            "Predicting batch 12/20\n",
            "Predicting batch 13/20\n",
            "Predicting batch 14/20\n",
            "Predicting batch 15/20\n",
            "Predicting batch 16/20\n",
            "Predicting batch 17/20\n",
            "Predicting batch 18/20\n",
            "Predicting batch 19/20\n",
            "Predicting batch 20/20\n",
            "The accuracy achieved for predictions using mnoukhov/gpt2-imdb-sentiment-classifier is 91.00%\n",
            "Predicting batch 1/20\n",
            "Predicting batch 2/20\n",
            "Predicting batch 3/20\n",
            "Predicting batch 4/20\n",
            "Predicting batch 5/20\n",
            "Predicting batch 6/20\n",
            "Predicting batch 7/20\n",
            "Predicting batch 8/20\n",
            "Predicting batch 9/20\n",
            "Predicting batch 10/20\n",
            "Predicting batch 11/20\n",
            "Predicting batch 12/20\n",
            "Predicting batch 13/20\n",
            "Predicting batch 14/20\n",
            "Predicting batch 15/20\n",
            "Predicting batch 16/20\n",
            "Predicting batch 17/20\n",
            "Predicting batch 18/20\n",
            "Predicting batch 19/20\n",
            "Predicting batch 20/20\n",
            "The accuracy achieved for predictions using abhishek/autonlp-imdb-roberta-base-3662644 is 93.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting batch 1/20\n",
            "Predicting batch 2/20\n",
            "Predicting batch 3/20\n",
            "Predicting batch 4/20\n",
            "Predicting batch 5/20\n",
            "Predicting batch 6/20\n",
            "Predicting batch 7/20\n",
            "Predicting batch 8/20\n",
            "Predicting batch 9/20\n",
            "Predicting batch 10/20\n",
            "Predicting batch 11/20\n",
            "Predicting batch 12/20\n",
            "Predicting batch 13/20\n",
            "Predicting batch 14/20\n",
            "Predicting batch 15/20\n",
            "Predicting batch 16/20\n",
            "Predicting batch 17/20\n",
            "Predicting batch 18/20\n",
            "Predicting batch 19/20\n",
            "Predicting batch 20/20\n",
            "The accuracy achieved for predictions using bert-base-uncased is 50.00%\n",
            "\n",
            "Comparing accuracies:\n",
            "GPT2 Accuracy: 91.00%\n",
            "RoBERTa Accuracy: 93.00%\n",
            "BERT Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7b478dlFNyKZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}